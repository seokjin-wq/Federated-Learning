{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_v0e31d_JTv"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from data import MNISTDataset, FederatedSampler\n",
        "from models import CNN, MLP\n",
        "from utils import arg_parser, average_weights, Logger\n",
        "\n",
        "#FedAvg 알고리즘 클래스 정의, 연합학습의 대표 알고리즘인 FedAvg 논문 기반\n",
        "class FedAvg:\n",
        "    \"\"\"Implementation of FedAvg\n",
        "    http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf\n",
        "    \"\"\"\n",
        "    #외부에서 하이퍼파라미터 등 설정값들을 args로 전달받음\n",
        "    def __init__(self, args: Dict[str, Any]):\n",
        "        #GPU 사용 가능 시 지정된 device 번호로 CUDA 사용, 그렇지 않으면 CPU 사용\n",
        "        self.args = args\n",
        "        self.device = torch.device(\n",
        "            f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        #결과 기록용 Logger 객체 초기화\n",
        "        self.logger = Logger(args)\n",
        "        #학습용 데이터 및 테스트 데이터를 FederatedSampler를 이용해 로딩\n",
        "        self.train_loader, self.test_loader = self._get_data(\n",
        "            root=self.args.data_root,\n",
        "            n_clients=self.args.n_clients,\n",
        "            n_shards=self.args.n_shards,\n",
        "            non_iid=self.args.non_iid,\n",
        "        )\n",
        "        #MLP 또는 CNN 중 하나를 선택해서 서버 초기 모델로 설정\n",
        "        if self.args.model_name == \"mlp\":\n",
        "            self.root_model = MLP(input_size=784, hidden_size=128, n_classes=10).to(\n",
        "                self.device\n",
        "            )\n",
        "            self.target_acc = 0.97\n",
        "        elif self.args.model_name == \"cnn\":\n",
        "            self.root_model = CNN(n_channels=1, n_classes=10).to(self.device)\n",
        "            self.target_acc = 0.99\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid model name, {self.args.model_name}\")\n",
        "        #목표 정확도 설정\n",
        "        self.reached_target_at = None  # type: int\n",
        "\n",
        "    ## [참여 skew 전략 삽입 위치] 클라이언트 참여 이력 저장 구조 초기화 필요\n",
        "    ## self.client_last_participated = [...]\n",
        "\n",
        "\n",
        "    ## [라벨 skew 전략 삽입 위치] 클라이언트 라벨 커버리지 계산 및 저장 필요\n",
        "    ## self.client_label_coverage = self._compute_label_coverage()\n",
        "\n",
        "    #연합학습용 데이터 분할 함수 정의\n",
        "    def _get_data(\n",
        "        self, root: str, n_clients: int, n_shards: int, non_iid: int\n",
        "    ) -> Tuple[DataLoader, DataLoader]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root (str): path to the dataset.\n",
        "            n_clients (int): number of clients.\n",
        "            n_shards (int): number of shards.\n",
        "            non_iid (int): 0: IID, 1: Non-IID\n",
        "\n",
        "        Returns:\n",
        "            Tuple[DataLoader, DataLoader]: train_loader, test_loader\n",
        "        \"\"\"\n",
        "        #MNIST 데이터셋을 학습/테스트용으로 불러옴\n",
        "        train_set = MNISTDataset(root=root, train=True)\n",
        "        test_set = MNISTDataset(root=root, train=False)\n",
        "        #클라이언트 수, shard 수, non-IID 여부에 따라 federated 샘플링 전략 적용\n",
        "        sampler = FederatedSampler(\n",
        "            train_set, non_iid=non_iid, n_clients=n_clients, n_shards=n_shards\n",
        "        )\n",
        "        #미니배치 생성\n",
        "        train_loader = DataLoader(train_set, batch_size=128, sampler=sampler)\n",
        "        test_loader = DataLoader(test_set, batch_size=128)\n",
        "\n",
        "        return train_loader, test_loader\n",
        "    #서버 모델을 복사해 클라이언트에서 학습 수행\n",
        "    def _train_client(\n",
        "        self, root_model: nn.Module, train_loader: DataLoader, client_idx: int\n",
        "    ) -> Tuple[nn.Module, float]:\n",
        "        \"\"\"Train a client model.\n",
        "\n",
        "        Args:\n",
        "            root_model (nn.Module): server model.\n",
        "            train_loader (DataLoader): client data loader.\n",
        "            client_idx (int): client index.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[nn.Module, float]: client model, average client loss.\n",
        "        \"\"\"\n",
        "        #서버 모델을 클라이언트용으로 깊은 복사 후 학습 모드로 전환\n",
        "        model = copy.deepcopy(root_model)\n",
        "        model.train()\n",
        "        #SGD 옵티마이저 설정\n",
        "        optimizer = torch.optim.SGD(\n",
        "            model.parameters(), lr=self.args.lr, momentum=self.args.momentum\n",
        "        )\n",
        "        #클라이언트 local epoch 수만큼 반복\n",
        "        for epoch in range(self.args.n_client_epochs):\n",
        "            epoch_loss = 0.0\n",
        "            epoch_correct = 0\n",
        "            epoch_samples = 0\n",
        "            #각 미니배치에 대해 forward → 손실 계산 → 역전파(backward) → 파라미터 업데이트 수행\n",
        "            for idx, (data, target) in enumerate(train_loader):\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                logits = model(data)\n",
        "                loss = F.nll_loss(logits, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                epoch_correct += (logits.argmax(dim=1) == target).sum().item()\n",
        "                epoch_samples += data.size(0)\n",
        "\n",
        "            # Calculate average accuracy and loss\n",
        "            epoch_loss /= idx\n",
        "            epoch_acc = epoch_correct / epoch_samples\n",
        "\n",
        "            print(\n",
        "                f\"Client #{client_idx} | Epoch: {epoch}/{self.args.n_client_epochs} | Loss: {epoch_loss} | Acc: {epoch_acc}\",\n",
        "                end=\"\\r\",\n",
        "            )\n",
        "        #학습된 클라이언트 모델과 평균 손실 반환\n",
        "        return model, epoch_loss / self.args.n_client_epochs\n",
        "    #서버 입장에서 전체 FedAvg 프로세스 실행\n",
        "    def train(self) -> None:\n",
        "        \"\"\"Train a server model.\"\"\"\n",
        "        train_losses = []\n",
        "        #전체 연합 라운드 반복\n",
        "        for epoch in range(self.args.n_epochs):\n",
        "            clients_models = []\n",
        "            clients_losses = []\n",
        "\n",
        "\n",
        "  ##[참여 skew 전략 삽입 위치] 참여 기록 기반 확률적 클라이언트 샘플링으로 개선 가능\n",
        "\n",
        "\n",
        "            #매 라운드에서 참여할 클라이언트 랜덤 선택\n",
        "            # Randomly select clients\n",
        "            m = max(int(self.args.frac * self.args.n_clients), 1)\n",
        "            idx_clients = np.random.choice(range(self.args.n_clients), m, replace=False)\n",
        "\n",
        "            # Train clients\n",
        "            self.root_model.train()\n",
        "\n",
        "            for client_idx in idx_clients:\n",
        "                # Set client in the sampler\n",
        "                self.train_loader.sampler.set_client(client_idx)\n",
        "\n",
        "  ## [참여 skew 전략 삽입 위치] 참여 간격 기반 보정 계수 계산 가능\n",
        "\n",
        "                # Train client\n",
        "                client_model, client_loss = self._train_client(\n",
        "                    root_model=self.root_model,\n",
        "                    train_loader=self.train_loader,\n",
        "                    client_idx=client_idx,\n",
        "                )\n",
        "                clients_models.append(client_model.state_dict())\n",
        "                clients_losses.append(client_loss)\n",
        "\n",
        "  ## [client size skew 전략 삽입 위치] 클라이언트별 샘플 수 측정 및 저장 필요\n",
        "\n",
        "\n",
        "  ## [label distribution skew 전략 삽입 위치] 클라이언트의 라벨 다양성(coverage) 확인 및 저장 필요\n",
        "\n",
        "\n",
        "  ## [통합 가중치 계산 삽입 위치] size × coverage × participation 등을 조합하여 가중치 생성\n",
        "\n",
        "\n",
        "  ## [평균화 전략 삽입 위치] average_weights 호출 시 위에서 계산한 가중치 활용하도록 수정 필요\n",
        "\n",
        "            #클라이언트 모델 파라미터들을 평균내어 서버 모델 업데이트\n",
        "            # Update server model based on clients models\n",
        "            updated_weights = average_weights(clients_models)\n",
        "            self.root_model.load_state_dict(updated_weights)\n",
        "\n",
        "            # Update average loss of this round\n",
        "            avg_loss = sum(clients_losses) / len(clients_losses)\n",
        "            train_losses.append(avg_loss)\n",
        "\n",
        "            #일정 라운드마다 테스트 수행 및 결과 기록, 목표 정확도 달성 시 조기 종료\n",
        "            if (epoch + 1) % self.args.log_every == 0:\n",
        "                # Test server model\n",
        "                total_loss, total_acc = self.test()\n",
        "                avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "                # Log results\n",
        "                logs = {\n",
        "                    \"train/loss\": avg_train_loss,\n",
        "                    \"test/loss\": total_loss,\n",
        "                    \"test/acc\": total_acc,\n",
        "                    \"round\": epoch,\n",
        "                }\n",
        "                if total_acc >= self.target_acc and self.reached_target_at is None:\n",
        "                    self.reached_target_at = epoch\n",
        "                    logs[\"reached_target_at\"] = self.reached_target_at\n",
        "                    print(\n",
        "                        f\"\\n -----> Target accuracy {self.target_acc} reached at round {epoch}! <----- \\n\"\n",
        "                    )\n",
        "\n",
        "                self.logger.log(logs)\n",
        "\n",
        "                # Print results to CLI\n",
        "                print(f\"\\n\\nResults after {epoch + 1} rounds of training:\")\n",
        "                print(f\"---> Avg Training Loss: {avg_train_loss}\")\n",
        "                print(\n",
        "                    f\"---> Avg Test Loss: {total_loss} | Avg Test Accuracy: {total_acc}\\n\"\n",
        "                )\n",
        "\n",
        "                # Early stopping\n",
        "                if self.args.early_stopping and self.reached_target_at is not None:\n",
        "                    print(f\"\\nEarly stopping at round #{epoch}...\")\n",
        "                    break\n",
        "    #서버 모델로 전체 테스트셋 평가 수행\n",
        "    def test(self) -> Tuple[float, float]:\n",
        "        \"\"\"Test the server model.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[float, float]: average loss, average accuracy.\n",
        "        \"\"\"\n",
        "        self.root_model.eval()\n",
        "\n",
        "        total_loss = 0.0\n",
        "        total_correct = 0.0\n",
        "        total_samples = 0\n",
        "        #\n",
        "        for idx, (data, target) in enumerate(self.test_loader):\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "            logits = self.root_model(data)\n",
        "            loss = F.nll_loss(logits, target)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += (logits.argmax(dim=1) == target).sum().item()\n",
        "            total_samples += data.size(0)\n",
        "\n",
        "        #테스트셋을 통해 손실과 정확도 계산\n",
        "        # calculate average accuracy and loss\n",
        "        total_loss /= idx\n",
        "        total_acc = total_correct / total_samples\n",
        "\n",
        "        return total_loss, total_acc\n",
        "\n",
        "#메인 실행부/ 외부 실행 시: 하이퍼파라미터를 파싱하여 FedAvg 인스턴스 생성 및 학습 실행\n",
        "if __name__ == \"__main__\":\n",
        "    args = arg_parser()\n",
        "    fed_avg = FedAvg(args)\n",
        "    fed_avg.train()"
      ]
    }
  ]
}